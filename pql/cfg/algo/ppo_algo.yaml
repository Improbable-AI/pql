defaults:
  - actor_critic.yaml
  - _self_

name: "PPO"
horizon_len: 16
batch_size: 32768
gamma: 0.99
act_class: DiagGaussianMLPPolicy
cri_class: MLPCritic
eval_freq: 20

update_times: 4
no_tgt_actor: True

use_gae: True
value_clip: True
lambda_gae_adv: 0.95
lambda_entropy: 0.0
ratio_clip: 0.2
